
---

# ğŸ§® MATH501: Modelling & Analytics for Data Science â€” End-to-End Statistical & Machine Learning Mastery  
> *From Seismic Event Classification to Airline Satisfaction & Carbon Sequestration â€” A Showcase of Statistical Rigor, Model Selection, and Business-Aligned Analytics*

![R](https://img.shields.io/badge/R-Advanced-blue?logo=r)  
![Python](https://img.shields.io/badge/Python-Supplementary-lightgrey?logo=python)  
![Machine Learning](https://img.shields.io/badge/ML-Decision%20Trees%20+%20KNN-orange)  
![Bayesian](https://img.shields.io/badge/Bayesian-JAGS%20+%20MCMC-purple)  
![Stats](https://img.shields.io/badge/Statistics-ANOVA%20+%20Tukey%20HSD-red)  
![Clustering](https://img.shields.io/badge/Unsupervised-KMeans-green)

## ğŸ“Š Project 1: Machine Learning â€” Seismic Event Classification (Earthquake vs Explosion)

### ğŸ¯ Business Problem
Classify seismic events with high accuracy and interpretability to support emergency response and national security decisions.

### ğŸ” Data Exploration
- Dataset: 37 observations, 2 features (`Body`, `Surface`), binary label (`type`: earthquake/explosion)
- **Imbalanced**: 26 earthquakes, 11 explosions
- **Key Insight**: Explosions have â†‘ `Body`, â†“ `Surface` â€” clear separation with moderate correlation (r=0.2)

![Scatterplot](screenshots/scatter_body_surface.png)  
*Fig: Explosions (red) cluster in high-Body, low-Surface region â€” ideal for classification.*

---

### ğŸ¤– Model Development & Tuning

#### â¤ K-Nearest Neighbors (KNN)
- **Tuned `k` via LOOCV** â†’ Optimal `k=3` (validation error = 0)
- **Test Error (LOOCV)**: 5.4%
- **Boundary**: Radial, smooth â€” less interpretable

![KNN Boundary](screenshots/knn_boundary.png)

#### â¤ Decision Tree
- **Optimal Size**: 3 terminal nodes (via cross-validation)
- **Rules**:  
  `IF Body < 5.675 AND Surface < 4.44 â†’ Explosion`  
  `ELSE â†’ Earthquake`
- **Test Error (LOOCV)**: **0%** â€” perfect classification
- **Why Chosen**: Zero error + full interpretability â†’ critical for high-risk decisions

![Decision Tree Rules](screenshots/decision_tree_rules.png)

---

### ğŸ“ˆ Model Comparison & Selection

| Metric               | Decision Tree | KNN     |
|----------------------|---------------|---------|
| **Test Error (LOOCV)** | **0.000**     | 0.054   |
| **False Positive Rate** | **0.000**     | 0.077   |
| **Interpretability**   | **High**      | Low     |
| **Recommended For**    | Mission-critical systems | General classification |

> âœ… **Final Selection**: Decision Tree â€” balances accuracy, simplicity, and risk mitigation.

---

### ğŸ” Bonus: Unsupervised Learning â€” K-Means Clustering
- **Goal**: Discover hidden structure without labels
- **Method**: Elbow Method â†’ Optimal `k=3`
- **Insight**: Cluster 3 â‰ˆ â€œExplosionsâ€; Clusters 1 & 2 = subtypes of â€œEarthquakesâ€ (high vs low Body/Surface)

![K-Means Clusters](screenshots/kmeans_clusters.png)

---

## ğŸ“ˆ Project 2: Frequentist Statistics â€” Airline Customer Satisfaction Analysis

### ğŸ¯ Business Question
Which airlines have statistically different customer satisfaction scores? Is Airline D >3 points better than B or C?

### ğŸ“Š Data Summary
- 4 Airlines (A, B, C, D), 15 customers each â†’ Balanced design
- Key Stats:  
  - **D**: Mean=6.33 (Highest)  
  - **B**: Mean=5.67  
  - **A & C**: ~4.4

![Boxplot](screenshots/airline_boxplot.png)

---

### ğŸ“‰ Statistical Testing

#### â¤ One-Way ANOVA
- **Hâ‚€**: All means equal â†’ **Rejected** (F=5.29, p=0.00278)  
  â†’ At least one airline differs significantly.

#### â¤ Tukey HSD (Pairwise Comparisons)
| Comparison | Diff | p-value   | Significant? |
|------------|------|-----------|--------------|
| **D vs A** | 2.00 | **0.007** | âœ… Yes       |
| **D vs C** | 1.87 | **0.014** | âœ… Yes       |
| **D vs B** | 0.67 | 0.676     | âŒ No        |
| **B vs A** | 1.33 | 0.123     | âŒ No        |

#### â¤ Hypothesis Test: Is D >3 points better than B or C?
- **D - B â‰¤ 3?** â†’ p=1.0 â†’ **No evidence D is >3 points better**  
- **D - C â‰¤ 3?** â†’ p=0.994 â†’ **No evidence D is >3 points better**

> ğŸ’¡ **Business Insight**: Airline D outperforms A and C â€” but not by 3+ points vs B or C. Marketing should avoid overclaiming.

---

## ğŸŒ± Project 3: Bayesian Statistics â€” Carbon Sequestration in Agriculture

### ğŸ¯ Business Problem
Which carbon capture treatment (T1-T5) is most effective? Do field locations (1-3) matter?

### ğŸ“Š Data Structure
- 3 Fields Ã— 5 Treatments â†’ 15 observations
- Response: Total Carbon Sequestration

---

### ğŸ“‰ Bayesian Two-Way ANOVA (JAGS + MCMC)

#### â¤ Model 1: Full Model (Field + Treatment Effects)
```r
yáµ¢â±¼ ~ N(Î¼ + Î±áµ¢ + Î²â±¼, ÏƒÂ²)
Î±â‚=0 (Field 1 baseline), Î²â‚=0 (T1 baseline)
```
- **Field Effects (Î±)**:  
  - Î±â‚‚=1.73 (95% HPD: -8.49, 11.32) â†’ Not significant (includes 0)  
  - Î±â‚ƒ=1.32 (95% HPD: -9.02, 10.97) â†’ Not significant  
  â†’ **Conclusion**: Field location has no detectable effect.

- **Treatment Effects (Î²)**:  
  - **T4**: Î²â‚„=30.67 (95% HPD: 18.32, 43.70) â†’ **Strongest effect**  
  - T3: Î²â‚ƒ=21.66, T5: Î²â‚…=18.05, T2: Î²â‚‚=12.83 â†’ All positive & significant (HPD >0)  
  â†’ **Conclusion**: T4 > T3 > T5 > T2 > T1

![Caterpillar Plot - Treatments](screenshots/caterpillar_treatments.png)

- **Model Fit**: DIC=119.5

---

### â¤ Model 2: Simpler Model (Treatment Only)
```r
yáµ¢â±¼ ~ N(Î¼ + Î²â±¼, ÏƒÂ²)  // No field effect
```
- **Treatment Effects**: Same ranking (T4 strongest)
- **Model Fit**: **DIC=108.6** â†’ Better fit + simpler â†’ **Preferred model**

> âœ… **Farmerâ€™s Decision**: Use **Treatment T4** â€” maximizes carbon capture. Field choice doesnâ€™t matter.

---

## ğŸ› ï¸ Technical Stack & Skills Demonstrated

| Area                  | Tools & Techniques                                                                 | Business Value                                  |
|-----------------------|------------------------------------------------------------------------------------|------------------------------------------------|
| **Machine Learning**  | Decision Trees, KNN, Hyperparameter Tuning (LOOCV), Confusion Matrices             | High-accuracy, interpretable classification    |
| **Frequentist Stats** | ANOVA, Tukey HSD, Linear Hypothesis Testing, p-values, Effect Sizes                | Validated comparisons, prevented false claims  |
| **Bayesian Stats**    | JAGS, MCMC, Prior/Posterior, HPD Intervals, DIC, Trace/Density Plots               | Quantified uncertainty, model comparison       |
| **Unsupervised**      | K-Means, Elbow Method, Cluster Interpretation                                      | Discovered hidden patterns in unlabeled data   |
| **Data Viz**          | ggplot2, Boxplots, Scatterplots, Histograms, Caterpillar Plots, Scree Plots         | Communicated insights to stakeholders          |
| **Programming**       | R (Advanced), `tree`, `e1071`, `aov`, `TukeyHSD`, `R2jags`, `ggplot2`, `dplyr`     | Reproducible, production-ready analysis        |
| **Critical Thinking** | Model Justification, Result Interpretation, Limitations, Business Context          | Trusted advisor, strategic decision support    |

---

## ğŸ“ Repository Structure

```
â”œâ”€â”€ MATH501_Report.pdf              # Full coursework report
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ seismic_classification.R    # ML: Decision Tree + KNN + Clustering
â”‚   â”œâ”€â”€ airline_anova.R             # Frequentist: ANOVA + Tukey + Hypothesis Tests
â”‚   â””â”€â”€ carbon_bayesian.R           # Bayesian: JAGS Models + MCMC Diagnostics
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ earthquake.txt              # Seismic event data
â”‚   â”œâ”€â”€ airline_satisfaction.csv    # Airline customer scores
â”‚   â””â”€â”€ carbon_sequestration.csv    # Agricultural treatment data
â”œâ”€â”€ screenshots/                    # Validation images (add your PNGs here)
â”‚   â”œâ”€â”€ scatter_body_surface.png
â”‚   â”œâ”€â”€ decision_tree_rules.png
â”‚   â”œâ”€â”€ airline_boxplot.png
â”‚   â”œâ”€â”€ caterpillar_treatments.png
â”‚   â””â”€â”€ kmeans_clusters.png
â””â”€â”€ README.md                       # You are here!
```

---

## â–¶ï¸ How to Run

1. Clone this repo:
   ```bash
   git clone https://github.com/yourusername/math501-modelling-analytics.git
   cd math501-modelling-analytics
   ```

2. Install R dependencies:
   ```r
   install.packages(c("tree", "e1071", "car", "multcomp", "R2jags", "ggplot2", "dplyr"))
   ```

3. Run scripts in RStudio or R console:
   ```r
   source("code/seismic_classification.R")
   source("code/airline_anova.R")
   source("code/carbon_bayesian.R")
   ```

## ğŸ“š References

- Ripley, B. (2023). `tree`: Classification and Regression Trees.  
- Meyer, D. et al. (2023). `e1071`: Misc Functions for Statistics.  
- Su, Y. & Yajima, M. (2024). `R2jags`: Bayesian Analysis with JAGS.  
- Wickham, H. (2016). `ggplot2`: Elegant Graphics for Data Analysis.  
- Venables, W.N. & Ripley, B.D. (2002). *Modern Applied Statistics with S*.

---

## ğŸ¤ Connect & Collaborate

ğŸ‘¤ **Author**: [Your Name]  
ğŸ“§ **Email**: [your.email@example.com]  
ğŸ’¼ **LinkedIn**: [linkedin.com/in/yourprofile]  
ğŸ“ **Program**: MSc Data Science and Business Analytics, University of Plymouth

> ğŸ‘‰ *Open to roles in: Statistical Modeling, Research Science, Advanced Analytics, Risk Modeling, Public Sector Data Science.*

---

âœ… **Last Updated**: April 2024  
âœ… **License**: MIT â€” Use, adapt, learn, and build upon this work!

---
